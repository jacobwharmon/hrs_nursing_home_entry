{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Missing</th>\n",
       "      <th>Percentage Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rafeduc</th>\n",
       "      <td>33700</td>\n",
       "      <td>15.105876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mapa_self</th>\n",
       "      <td>26407</td>\n",
       "      <td>11.836821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rameduc</th>\n",
       "      <td>21589</td>\n",
       "      <td>9.677174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climsa_self</th>\n",
       "      <td>21331</td>\n",
       "      <td>9.561526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mealsa_self</th>\n",
       "      <td>18080</td>\n",
       "      <td>8.104280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total Missing  Percentage Missing\n",
       "rafeduc              33700           15.105876\n",
       "mapa_self            26407           11.836821\n",
       "rameduc              21589            9.677174\n",
       "climsa_self          21331            9.561526\n",
       "mealsa_self          18080            8.104280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../final_data/clean_model_data.csv')\n",
    "\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().mean()) * 100\n",
    "\n",
    "# Combine results into a summary dataframe\n",
    "summary = pd.DataFrame({\n",
    "    \"Total Missing\": missing_summary,\n",
    "    \"Percentage Missing\": missing_percentage\n",
    "}).sort_values(by=\"Total Missing\", ascending=False)\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and features\n",
    "y = df['nhmliv_self_next_wave'].to_numpy()\n",
    "X = df.iloc[:, list(df.columns).index('nhmliv_self_next_wave')+1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n",
      "\n",
      "=== Cross-Validation Results ===\n",
      "Mean Accuracy: 0.9865\n",
      "Standard Deviation of Accuracy: 0.0001\n",
      "Mean F1 Score (Weighted): 0.9806\n",
      "Standard Deviation of F1 Score: 0.0000\n",
      "Mean McFadden's Pseudo R^2: 0.2715\n",
      "Standard Deviation of McFadden's Pseudo R^2: 0.0032\n"
     ]
    }
   ],
   "source": [
    "### MODEL 1) VANILLA LOGISTIC REGRESSION\n",
    "\n",
    "import numpy as np\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Imputing NaNs\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Oversampling Minority Class\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, log_loss, f1_score\n",
    "# Preprocessing continuous scales for Logistic Regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Opting to impute missing values with the mean for Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=720)\n",
    "\n",
    "# Results storage\n",
    "fold_accuracies = []\n",
    "fold_conf_matrices = []\n",
    "fold_reports = []\n",
    "fold_pseudo_r2 = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold CV\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split the dataset into training and testing subsets for the current fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Apply oversampling to the training data only\n",
    "    ros = RandomOverSampler(random_state=720)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Fit and Predict\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Compute log-likelihoods for McFadden's pseudo R^2\n",
    "    log_likelihood_full = -log_loss(y_train, pipeline.predict_proba(X_train), normalize=False)\n",
    "    log_likelihood_null = -log_loss(y_train, np.full_like(y_train, y_train.mean()), normalize=False)\n",
    "    mcfadden_r2 = 1 - (log_likelihood_full / log_likelihood_null)\n",
    "    fold_pseudo_r2.append(mcfadden_r2)\n",
    "\n",
    "    # Store results\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_conf_matrices.append(conf_matrix)\n",
    "    fold_reports.append(class_report)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    # Print results for this fold\n",
    "    # print(f\"Fold Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Fold F1 Score (Weighted): {f1:.4f}\")\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(conf_matrix)\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(class_report)\n",
    "    # print(f\"McFadden's Pseudo R^2: {mcfadden_r2:.4f}\")\n",
    "\n",
    "# Summarize cross-validation results\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score (Weighted): {np.mean(fold_f1_scores):.4f}\")\n",
    "print(f\"Standard Deviation of F1 Score: {np.std(fold_f1_scores):.4f}\")\n",
    "print(f\"Mean McFadden's Pseudo R^2: {np.mean(fold_pseudo_r2):.4f}\")\n",
    "print(f\"Standard Deviation of McFadden's Pseudo R^2: {np.std(fold_pseudo_r2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-Validation Results ===\n",
      "Mean Accuracy: 0.9865\n",
      "Standard Deviation of Accuracy: 0.0001\n",
      "Mean F1 Score (Weighted): 0.9806\n",
      "Standard Deviation of F1 Score: 0.0001\n",
      "Mean McFadden's Pseudo R^2: 0.2717\n",
      "Standard Deviation of McFadden's Pseudo R^2: 0.0031\n"
     ]
    }
   ],
   "source": [
    "### MODEL 2) ELASTIC NET REGULARIZATION FOR LOGISTIC REGRESSION\n",
    "\n",
    "# Opting to impute missing values with the mean for Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic', LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000))\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=720)\n",
    "\n",
    "# Results storage\n",
    "fold_accuracies = []\n",
    "fold_conf_matrices = []\n",
    "fold_reports = []\n",
    "fold_pseudo_r2 = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold CV\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split the dataset into training and testing subsets for the current fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Apply oversampling to the training data only\n",
    "    ros = RandomOverSampler(random_state=720)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Fit and Predict\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Compute log-likelihoods for McFadden's pseudo R^2\n",
    "    log_likelihood_full = -log_loss(y_train, pipeline.predict_proba(X_train), normalize=False)\n",
    "    log_likelihood_null = -log_loss(y_train, np.full_like(y_train, y_train.mean()), normalize=False)\n",
    "    mcfadden_r2 = 1 - (log_likelihood_full / log_likelihood_null)\n",
    "    fold_pseudo_r2.append(mcfadden_r2)\n",
    "\n",
    "    # Store results\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_conf_matrices.append(conf_matrix)\n",
    "    fold_reports.append(class_report)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Summarize cross-validation results\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score (Weighted): {np.mean(fold_f1_scores):.4f}\")\n",
    "print(f\"Standard Deviation of F1 Score: {np.std(fold_f1_scores):.4f}\")\n",
    "print(f\"Mean McFadden's Pseudo R^2: {np.mean(fold_pseudo_r2):.4f}\")\n",
    "print(f\"Standard Deviation of McFadden's Pseudo R^2: {np.std(fold_pseudo_r2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n",
      "\n",
      "=== Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8123\n",
      "Standard Deviation of Accuracy: 0.0019\n",
      "Mean F1 Score (Weighted): 0.8848\n",
      "Standard Deviation of F1 Score: 0.0012\n",
      "Mean Pseudo R²: 0.4199\n",
      "Standard Deviation of Pseudo R²: 0.0040\n"
     ]
    }
   ],
   "source": [
    "### MODEL 3) Random Forest\n",
    "\n",
    "# Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Opting to impute missing values with the mean for Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('random_forest', RandomForestClassifier(\n",
    "        random_state=720,\n",
    "        n_estimators=50,\n",
    "        max_depth=5,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='sqrt',\n",
    "        oob_score=True,\n",
    "    ))\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=720)\n",
    "\n",
    "# Results storage\n",
    "fold_accuracies = []\n",
    "fold_conf_matrices = []\n",
    "fold_reports = []\n",
    "fold_pseudo_r2 = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold CV\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split the dataset into training and testing subsets for the current fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Apply oversampling to the training data only\n",
    "    ros = RandomOverSampler(random_state=720)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Fit and Predict\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Compute McFadden's pseudo R^2\n",
    "    log_likelihood_full = -log_loss(y_test, y_pred_proba, normalize=False)\n",
    "    y_test_baseline_prob = np.full((len(y_test), len(np.unique(y_train))), 1 / len(np.unique(y_train)))  # Null model: uniform probabilities\n",
    "    log_likelihood_null = -log_loss(y_test, y_test_baseline_prob, normalize=False)\n",
    "    pseudo_r2 = 1 - (log_likelihood_full / log_likelihood_null)\n",
    "    fold_pseudo_r2.append(pseudo_r2)\n",
    "\n",
    "    # Store results\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_conf_matrices.append(conf_matrix)\n",
    "    fold_reports.append(class_report)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Summarize cross-validation results\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score (Weighted): {np.mean(fold_f1_scores):.4f}\")\n",
    "print(f\"Standard Deviation of F1 Score: {np.std(fold_f1_scores):.4f}\")\n",
    "print(f\"Mean Pseudo R²: {np.mean(fold_pseudo_r2):.4f}\")\n",
    "print(f\"Standard Deviation of Pseudo R²: {np.std(fold_pseudo_r2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:10:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:10:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:10:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:10:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:11:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:11:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:11:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\health_index\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:11:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8513\n",
      "Standard Deviation of Accuracy: 0.0016\n",
      "Mean F1 Score (Weighted): 0.9083\n",
      "Standard Deviation of F1 Score: 0.0009\n",
      "Mean McFadden's Pseudo R^2: 0.5561\n",
      "Standard Deviation of McFadden's Pseudo R^2: 0.0045\n"
     ]
    }
   ],
   "source": [
    "### MODEL 4) XGBOOST\n",
    "\n",
    "# Model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Opting to impute missing values with the mean for XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('xgboost', XGBClassifier(\n",
    "        random_state=720,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=1,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=100  # Lower for faster testing\n",
    "    ))\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=720)\n",
    "\n",
    "# Results storage\n",
    "fold_accuracies = []\n",
    "fold_conf_matrices = []\n",
    "fold_reports = []\n",
    "fold_pseudo_r2 = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "# Perform Stratified K-Fold CV\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split the dataset into training and testing subsets for the current fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Apply oversampling to the training data only\n",
    "    ros = RandomOverSampler(random_state=720)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Fit and Predict\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Fit and Predict\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=False)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Compute log-likelihoods for McFadden's pseudo R^2\n",
    "    log_likelihood_full = -log_loss(y_train_resampled, pipeline.predict_proba(X_train_resampled), normalize=False)\n",
    "    log_likelihood_null = -log_loss(y_train_resampled, np.full_like(y_train_resampled, y_train_resampled.mean()), normalize=False)\n",
    "    mcfadden_r2 = 1 - (log_likelihood_full / log_likelihood_null)\n",
    "    fold_pseudo_r2.append(mcfadden_r2)\n",
    "\n",
    "    # Store results\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_conf_matrices.append(conf_matrix)\n",
    "    fold_reports.append(class_report)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Summarize cross-validation results\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score (Weighted): {np.mean(fold_f1_scores):.4f}\")\n",
    "print(f\"Standard Deviation of F1 Score: {np.std(fold_f1_scores):.4f}\")\n",
    "print(f\"Mean McFadden's Pseudo R^2: {np.mean(fold_pseudo_r2):.4f}\")\n",
    "print(f\"Standard Deviation of McFadden's Pseudo R^2: {np.std(fold_pseudo_r2):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
